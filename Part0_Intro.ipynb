{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS236781: Deep Learning on Computational Accelerators\n",
    "# Homework Assignment 3\n",
    "\n",
    "Faculty of Computer Science, Technion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted by:\n",
    "\n",
    "| #       |              Name |             Id |             email |\n",
    "|---------|-------------------|----------------|------------------ |\n",
    "|Student 1|  [your name here] | [your id here] | [your email here] |\n",
    "|Student 2|  [your name here] | [your id here] | [your email here] |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we'll learn to generate text with a deep multilayer RNN network based on GRU cells.\n",
    "Then we'll focus our attention on image generation using a variational autoencoder.\n",
    "We will then shift our focus to sentiment analysis: First by training a transformer-style encoder, and then by fine-tuning a pre-trained model from Hugging Face."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Guidelines\n",
    "\n",
    "- Please read the [getting started page](https://vistalab-technion.github.io/cs236781/assignments/getting-started) on the course website. It explains how to **setup, run and submit** the assignment.\n",
    "- This assignment requires running on GPU-enabled hardware. Please read the [course servers usage guide](https://vistalab-technion.github.io/cs236781/assignments/hpc-servers). It explains how to use and run your code on the course servers to benefit from training with GPUs.\n",
    "- The text and code cells in these notebooks are intended to guide you through the\n",
    "  assignment and help you verify your solutions.\n",
    "  The notebooks **do not need to be edited** at all (outside of a small code block in part 4).\n",
    "  The only exception is to fill your name(s) in the above cell before submission, and implementing a small code block in Part 4.\n",
    "  Please do not remove sections or change the order of any cells.\n",
    "- All your code (and even answers to questions) should be written in the files\n",
    "  within the python package corresponding the assignment number (`hw1`, `hw2`, etc).\n",
    "  You can of course use any editor or IDE to work on these files.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Part1: Sequence Models](#part1)\n",
    "    - [Text generation with a char-level RNN](#part1_1)\n",
    "    - [Obtaining the corpus](#part1_2)\n",
    "    - [Data Preprocessing](#part1_3)\n",
    "    - [Dataset Creation](#part1_4)\n",
    "    - [Model Implementation](#part1_5)\n",
    "    - [Generating text by sampling](#part1_6)\n",
    "    - [Training](#part1_7)\n",
    "    - [Generating a work of art](#part1_8)\n",
    "    - [Questions](#part1_9)\n",
    "- [Part 2: Variational Autoencoder](#part2):\n",
    "    - [Obtaining the dataset](#part2_1)\n",
    "    - [The Variational Autoencoder](#part2_2)\n",
    "    - [Model Implementation](#part2_3)\n",
    "    - [Loss Implementation](#part2_4)\n",
    "    - [Sampling](#part2_5)\n",
    "    - [Training](#part2_6)\n",
    "    - [Questions](#part2_7)\n",
    "- [Part 3: Transformer Encoder](#part3)\n",
    "    - [Reminder: scaled dot product attention](#part3_1)\n",
    "    - [Sliding window attention](#part3_2)\n",
    "    - [Multihead Sliding window attention](#part3_3)\n",
    "    - [Sentiment analysis](#part3_4)\n",
    "    - [Obtaining the dataset](#part3_5)\n",
    "    - [Tokenizer](#part3_6)\n",
    "    - [Transformer Encoder](#part3_7)\n",
    "    - [Training](#part3_8)\n",
    "    - [Questions](#part3_9)\n",
    "- [Part 4: Fine-tuning a pretrained language model](#part4)\n",
    "    - [Loading the dataset](#part4_1)\n",
    "    - [Tokenizer](#part4_2)\n",
    "    - [Loading pre-trained model](#part4_3)\n",
    "    - [Fine-tuning](#part4_4)\n",
    "    - [Questions](#part4_5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
